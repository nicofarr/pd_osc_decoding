{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "from matplotlib import pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "from mne.viz import plot_compare_evokeds\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import os \n",
    "from andante_pd_ft2mne import import2mne  \n",
    "\n",
    "#matfile = '/Users/nicolasfarrugia/Documents/recherche/PD/PDNewAnalysis/data/eeg_task/analysis/data_newfilt/probands/data_cleaned_newfilt_subj_01k101k1.mat'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on all subjects \n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datadir = '/Users/nicolasfarrugia/Documents/recherche/PD/PDNewAnalysis/data/eeg_task/analysis/data_newfilt/'\n",
    "#datadir = '/Users/nicolasfarrugia/Documents/recherche/PD/PDNewAnalysis/data/eeg_task/analysis/data_ica_cleaned/'\n",
    "\n",
    "datadir = '/home/brain/datasets/mpi_pd_cueing/data_ica_cleaned/'\n",
    "resultdir = '/home/brain/datasets/mpi_pd_cueing/results/'\n",
    "\n",
    "import os \n",
    "\n",
    "allcontrols = os.listdir(os.path.join(datadir,'probands'))\n",
    "allpatients = os.listdir(os.path.join(datadir,'patients'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "def mann_witt_matrix(mat,y):\n",
    "    lcol = mat.shape[1]\n",
    "    pvalue = np.zeros((lcol,lcol))\n",
    "    statU = np.zeros((lcol,lcol))\n",
    "    probav = np.zeros((2,lcol,lcol))\n",
    "    unik = (np.unique(y))\n",
    "    valstd=  unik[0]\n",
    "    valdev= unik[1]\n",
    "    for i in range(lcol):\n",
    "        for j in range(lcol):\n",
    "            #curp_S=mat[:,i,j,0]\n",
    "            #curp_D=mat[:,i,j,1]\n",
    "            curp_S_S=mat[(y==valstd),i,j,0]\n",
    "            curp_S_D=mat[(y==valdev),i,j,0]\n",
    "            \n",
    "            stat,pval = mannwhitneyu(curp_S_S,curp_S_D,alternative='two-sided')\n",
    "            statU[i,j]=stat\n",
    "            pvalue[i,j]=pval\n",
    "            \n",
    "            probav[0,i,j]= np.mean(curp_S_S,axis=0)\n",
    "            probav[1,i,j]= np.mean(curp_S_D,axis=0)\n",
    "    \n",
    "    return statU,pvalue,probav\n",
    "            \n",
    "def mann_witt_all(bigmat,y):\n",
    "    resU = []\n",
    "    resP = []\n",
    "    resprobav = []\n",
    "    for mat in bigmat:\n",
    "        U,pval,probav = mann_witt_matrix(mat,y)\n",
    "        \n",
    "        resU.append(U)\n",
    "        resP.append(pval)\n",
    "        resprobav.append(probav)\n",
    "        \n",
    "    return np.stack(resU),np.stack(resP),np.stack(resprobav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from andante_pd_ft2mne import import2mne  \n",
    "from mne import Epochs,EpochsArray\n",
    "from mne.channels import read_montage\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import mne\n",
    "from mne.datasets import sample\n",
    "from mne.decoding import GeneralizingEstimator\n",
    "from mne.decoding import CSP\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def timegen_process_2x2(matfile,ncv=5,metric='accuracy',tmin=-0.05,tmax=0.15,\n",
    "                        condnames=['iso_std','iso_dev'],condnames_2=['rnd_std','rnd_dev']):\n",
    "    subjid = matfile[-8:-4]\n",
    "    print(\"Subject : %s \" % subjid)\n",
    "    \n",
    "    ## Open file \n",
    "    mneEpochs = import2mne(matfile)\n",
    "    mneEpochs_short = mneEpochs.crop(tmin=tmin,tmax=tmax)\n",
    "    \n",
    "    \n",
    "    montage = read_montage('standard_1020')\n",
    "\n",
    "    mneEpochs_short.set_montage(montage)\n",
    "\n",
    "    ## Perform Supervised Learning using Temporal Generalization \n",
    "    \n",
    "    epochs = mneEpochs_short[condnames]\n",
    "    epochs_cond2 = mneEpochs_short[condnames_2]\n",
    "    \n",
    "    clf = make_pipeline(StandardScaler(),LogisticRegression())\n",
    "\n",
    "    time_gen = GeneralizingEstimator(clf, scoring=metric, n_jobs=-2)\n",
    "\n",
    "    time_gen_cond2 = GeneralizingEstimator(clf, scoring=metric, n_jobs=-2)\n",
    "\n",
    "    \n",
    "    # Get the labels\n",
    "    labels = epochs.events[:, -1]\n",
    "    labels_2 = epochs_cond2.events[:, -1]\n",
    "\n",
    "    # Cross validator\n",
    "    cv = StratifiedKFold(n_splits=ncv, shuffle=True, random_state=42)\n",
    "\n",
    "    \n",
    "    ### We will calculate a 2x2 matrix\n",
    "    ### First, let's cal\n",
    "    \n",
    "    \n",
    "    scores1_1 = []\n",
    "    scores1_2 = []\n",
    "    scores2_1 = []\n",
    "    scores2_2 = []\n",
    "    \n",
    "    proba1_1 = []\n",
    "    proba1_2 = []\n",
    "    proba2_1 = []\n",
    "    proba2_2 = []\n",
    "    \n",
    "    U1_1 = []\n",
    "    U1_2 = []\n",
    "    U2_1 = []\n",
    "    U2_2 = []\n",
    "    \n",
    "    allpval1_1=[]\n",
    "    allpval1_2=[]\n",
    "    allpval2_1=[]\n",
    "    allpval2_2=[]\n",
    "\n",
    "    \n",
    "    for train, test in cv.split(epochs, labels):\n",
    "        for train2, test2 in cv.split(epochs_cond2,labels_2):\n",
    "\n",
    "            # Train classifier1 on train data of condition 1 \n",
    "            time_gen.fit(X=epochs[train].get_data(), y=labels[train])\n",
    "\n",
    "            # Train classifier2 on train data of condition 2 \n",
    "            time_gen_cond2.fit(X=epochs_cond2[train2].get_data(), y=labels_2[train2])\n",
    "            \n",
    "            # Test Classifier1 on test data of condition 1\n",
    "            scores1_1.append(time_gen.score(X=epochs[test].get_data(),y=labels[test]))\n",
    "            \n",
    "            U,allpval,proba_av = mann_witt_matrix(time_gen.predict_proba(X=epochs[test].get_data()),y=labels[test])\n",
    "            proba1_1.append(proba_av)\n",
    "            U1_1.append(U)\n",
    "            allpval1_1.append(allpval)\n",
    "            \n",
    "            \n",
    "            # Test Classifier1 on test data of condition 2\n",
    "            scores1_2.append(time_gen.score(X=epochs_cond2[test2].get_data(),y=labels_2[test2]))\n",
    "            \n",
    "            U,allpval,proba_av = mann_witt_matrix(time_gen.predict_proba(X=epochs_cond2[test2].get_data()),y=labels_2[test2])\n",
    "            proba1_2.append(proba_av)\n",
    "            U1_2.append(U)\n",
    "            allpval1_2.append(allpval)\n",
    "            \n",
    "            # Test Classifier2 on test data of condition 1\n",
    "            scores2_1.append(time_gen_cond2.score(X=epochs[test].get_data(),y=labels[test]))\n",
    "            \n",
    "            U,allpval,proba_av = mann_witt_matrix(time_gen_cond2.predict_proba(X=epochs[test].get_data()),y=labels[test])\n",
    "            proba2_1.append(proba_av)\n",
    "            U2_1.append(U)\n",
    "            allpval2_1.append(allpval)\n",
    "            \n",
    "            # Test Classifier2 on test data of condition 2\n",
    "            scores2_2.append(time_gen_cond2.score(X=epochs_cond2[test2].get_data(),y=labels_2[test2]))\n",
    "            \n",
    "            U,allpval,proba_av = mann_witt_matrix(time_gen_cond2.predict_proba(X=epochs_cond2[test2].get_data()),y=labels_2[test2])\n",
    "            proba2_2.append(proba_av)\n",
    "            U2_2.append(U)\n",
    "            allpval2_2.append(allpval)\n",
    "\n",
    "        \n",
    "    scores1_1 = np.stack(scores1_1)\n",
    "    \n",
    "    scores1_2 = np.stack(scores1_2)\n",
    "    \n",
    "    scores2_1 = np.stack(scores2_1)\n",
    "    \n",
    "    scores2_2 = np.stack(scores2_2)\n",
    "    \n",
    "    proba1_1 = np.stack(proba1_1)\n",
    "    \n",
    "    proba1_2 = np.stack(proba1_2)\n",
    "    \n",
    "    proba2_1 = np.stack(proba2_1)\n",
    "    \n",
    "    proba2_2 = np.stack(proba2_2)\n",
    "    \n",
    "    U1_1 = np.stack(U1_1)\n",
    "    U1_2 = np.stack(U1_2)\n",
    "    U2_1 = np.stack(U2_1)\n",
    "    U2_2 = np.stack(U2_2)\n",
    "    \n",
    "    allpval1_1 = np.stack(allpval1_1)\n",
    "    allpval1_2 = np.stack(allpval1_2)\n",
    "    allpval2_1 = np.stack(allpval2_1)\n",
    "    allpval2_2 = np.stack(allpval2_2)\n",
    "    \n",
    "    scores = np.stack([scores1_1,scores1_2,scores2_1,scores2_2])\n",
    "    allU = np.stack([U1_1,U1_2,U2_1,U2_2])\n",
    "    allpvals = np.stack([allpval1_1,allpval1_2,allpval2_1,allpval2_2])\n",
    "    allproba = np.stack([proba1_1,proba1_2,proba2_1,proba2_2])\n",
    "     \n",
    "    return scores,allU,allpvals,allproba,epochs.times[[0, -1, 0, -1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formal structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject : 13k1 \n",
      "633 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "temporal = ['iso_std','rnd_std']\n",
    "formal_iso = ['iso_std','iso_dev']\n",
    "formal_rnd = ['rnd_std','rnd_dev']\n",
    "\n",
    "tmin = -0.05\n",
    "tmax = 0.52\n",
    "ncv  = 2\n",
    "\n",
    "#tmin = 0.25\n",
    "#tmax = 0.40\n",
    "#ncv  = 2\n",
    "\n",
    "allscores_formal = []\n",
    "allproba_formal = []\n",
    "\n",
    "allU_formal = []\n",
    "allpval_formal= []\n",
    "\n",
    "listofsubj = [allcontrols,allpatients]\n",
    "\n",
    "savenpz = True\n",
    "\n",
    "for kk,group in enumerate(['probands','patients']):\n",
    "\n",
    "    curlist = listofsubj[kk]\n",
    "    \n",
    "    for matfile in curlist[5:10]:\n",
    "        curfile = os.path.join(datadir,group,matfile)\n",
    "        subjid = curfile[-8:-4]\n",
    "\n",
    "        allscores,allU,allpvals,allproba,timepoints= timegen_process_2x2(curfile,metric='roc_auc',tmin=tmin,tmax=tmax,\n",
    "                                                 ncv=ncv,condnames=formal_iso,condnames_2=formal_rnd)\n",
    "        \n",
    "       \n",
    "\n",
    "        if savenpz:\n",
    "            np.savez_compressed(os.path.join(resultdir,\"180802_%s_formal_conditionwise.npz\" % subjid),\n",
    "                                scores=allscores,\n",
    "                                proba = allproba,\n",
    "                                U = allU,\n",
    "                                pval=allpvals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
